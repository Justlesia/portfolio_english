{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/><font size=\"6\"><b>MegaFon Accelerator. Classification. </b></font>.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the project\n",
    "\n",
    "## Formulation of the problem\n",
    "\n",
    "It is necessary to build a model that predicts which of the three segments (0,1,2) each subscriber belongs to.\n",
    "\n",
    "## Description of data\n",
    "\n",
    "The training sample contest_train.csv consists of the following columns:\n",
    "\n",
    "* ID - subscriber identifier.\n",
    "* TARGET - segment corresponding to the subscriber.\n",
    "* FEATURE_0…FEATURE_259 — subscriber characteristics.\n",
    "\n",
    "* The test sample contest_test.csv consists of the ID column followed by the FEATURE_0 ... FEATURE_259 columns\n",
    "\n",
    "*Prediction accuracy is estimated by macro-f1_score.*\n",
    "\n",
    "\n",
    "*Public/Private distribution - 50%/50%*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"0.\"></a><br/>\n",
    "<font size=\"4\"><b>0. Подгрузка библиотек и самописные функции</b></font>.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics  import f1_score\n",
    "from sklearn.metrics  import precision_score\n",
    "from sklearn.metrics  import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from termcolor import colored\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats as st\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определяем болд\n",
    "def bold(): \n",
    "    return \"\\033[1m\"\n",
    "\n",
    "def bold_end(): \n",
    "    return \"\\033[0m\"\n",
    "\n",
    "#Ставим формат для нумериков\n",
    "pd.options.display.float_format = '{: >10.2f}'.format\n",
    "\n",
    "#Убираем ворнинги\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#**Function print_basic_info, to display information about the array and its variables.**\n",
    "\n",
    "#* base - database name\n",
    "#* info - 1: output information about the array, other: no output\n",
    "#* describe - 1: output description of array variables, other: no output\n",
    "#* duplicat - 1: print the number of full duplicates\n",
    "#* head - n: base example output (output n - lines), n < 1: no output\n",
    "\n",
    "def print_basic_info(base, info, describe, duplicate, head):\n",
    "    if info == 1:\n",
    "        print(\"\\n\", bold(), colored('info','green'), bold_end(), \"\\n\")\n",
    "        print(base.info())\n",
    "    if head >= 1:\n",
    "        print(\"\\n\", bold(),colored('head','green'),bold_end())\n",
    "        display(base.head(head))\n",
    "    if describe == 1:\n",
    "        print(\"\\n\", bold(),colored('describe','green'),bold_end(),\"\\n\")\n",
    "        for i in base.columns:\n",
    "            print(\"\\n\", bold(), colored(i,'blue'),bold_end(),\"\\n\", base[i].describe())\n",
    "    if duplicate == 1:\n",
    "        print(\"\\n\", bold(),colored('duplicated','green'),bold_end(),\"\\n\")\n",
    "        print(base[base.duplicated() == True][base.columns[0]].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__Function ft_namecount__, to display the name of the variable, the frequency normalized table and the description of the variable.\n",
    "\n",
    "#5 input parameters:\n",
    "\n",
    "#* *base* - database name\n",
    "#* *index* - variable name in the database\n",
    "#* *table* - 1: output frequency normalized table, 0: no output\n",
    "#* *sort* - 1: sort table by variable labels, 0: no sort\n",
    "#* *describe* - 1: output variable description, 0: no output\n",
    "\n",
    "def ft_name_count (base, name , table, sort, describe):\n",
    "    print(bold(), colored(name,'blue') , bold_end(), \"\\n\")\n",
    "    if table != 0:\n",
    "        s = (base[name].value_counts(normalize=True))\n",
    "        if sort != 0:\n",
    "            s.sort_index(inplace=True)\n",
    "        print(s)\n",
    "    if describe != 0:\n",
    "        print(base[name].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"1.\"></a><br/>\n",
    "<font size=\"6\"><b>1. Подготовка данных</b></font>.<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Открываем**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I work locally, online is different\n",
    "\n",
    "contest_train = pd.read_csv('datasets/contest_train.csv', sep=',',decimal='.' , index_col= 'ID')\n",
    "contest_test = pd.read_csv('datasets/contest_test.csv', sep=',',decimal='.', index_col = 'ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \u001b[1m \u001b[32minfo\u001b[0m \u001b[0m \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24521 entries, 0d1c880d23ff018 to 5044ce165577a9f\n",
      "Columns: 261 entries, TARGET to FEATURE_259\n",
      "dtypes: float64(260), int64(1)\n",
      "memory usage: 49.0+ MB\n",
      "None\n",
      "\n",
      " \u001b[1m \u001b[32mhead\u001b[0m \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "      <th>FEATURE_0</th>\n",
       "      <th>FEATURE_1</th>\n",
       "      <th>FEATURE_2</th>\n",
       "      <th>FEATURE_3</th>\n",
       "      <th>FEATURE_4</th>\n",
       "      <th>FEATURE_5</th>\n",
       "      <th>FEATURE_6</th>\n",
       "      <th>FEATURE_7</th>\n",
       "      <th>FEATURE_8</th>\n",
       "      <th>...</th>\n",
       "      <th>FEATURE_250</th>\n",
       "      <th>FEATURE_251</th>\n",
       "      <th>FEATURE_252</th>\n",
       "      <th>FEATURE_253</th>\n",
       "      <th>FEATURE_254</th>\n",
       "      <th>FEATURE_255</th>\n",
       "      <th>FEATURE_256</th>\n",
       "      <th>FEATURE_257</th>\n",
       "      <th>FEATURE_258</th>\n",
       "      <th>FEATURE_259</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0d1c880d23ff018</th>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-114.53</td>\n",
       "      <td>-17.22</td>\n",
       "      <td>...</td>\n",
       "      <td>39.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>223.12</td>\n",
       "      <td>290.02</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579ba37fd82c1f</th>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>329.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>25.00</td>\n",
       "      <td>82.00</td>\n",
       "      <td>479.62</td>\n",
       "      <td>611.65</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790086f721c7f5e</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.43</td>\n",
       "      <td>-6.68</td>\n",
       "      <td>...</td>\n",
       "      <td>119.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>352.27</td>\n",
       "      <td>564.57</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 261 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 TARGET  FEATURE_0  FEATURE_1  FEATURE_2  FEATURE_3  \\\n",
       "ID                                                                    \n",
       "0d1c880d23ff018       1       2.00       2.00       0.00       0.00   \n",
       "1579ba37fd82c1f       0       1.00       1.00       0.00       0.00   \n",
       "790086f721c7f5e       1       0.00       0.00       0.00       0.00   \n",
       "\n",
       "                 FEATURE_4  FEATURE_5  FEATURE_6  FEATURE_7  FEATURE_8  ...  \\\n",
       "ID                                                                      ...   \n",
       "0d1c880d23ff018       0.00       0.00       0.00    -114.53     -17.22  ...   \n",
       "1579ba37fd82c1f       1.00       0.00       0.00     329.83        NaN  ...   \n",
       "790086f721c7f5e       0.00       0.00       0.00      17.43      -6.68  ...   \n",
       "\n",
       "                 FEATURE_250  FEATURE_251  FEATURE_252  FEATURE_253  \\\n",
       "ID                                                                    \n",
       "0d1c880d23ff018        39.00         2.00       223.12       290.02   \n",
       "1579ba37fd82c1f        25.00        82.00       479.62       611.65   \n",
       "790086f721c7f5e       119.00         0.00       352.27       564.57   \n",
       "\n",
       "                 FEATURE_254  FEATURE_255  FEATURE_256  FEATURE_257  \\\n",
       "ID                                                                    \n",
       "0d1c880d23ff018         1.00         1.00         0.00         1.00   \n",
       "1579ba37fd82c1f         0.00         1.00         0.00         1.00   \n",
       "790086f721c7f5e         1.00         1.00         0.00         1.00   \n",
       "\n",
       "                 FEATURE_258  FEATURE_259  \n",
       "ID                                         \n",
       "0d1c880d23ff018         2.00         2.00  \n",
       "1579ba37fd82c1f         1.00         1.00  \n",
       "790086f721c7f5e         1.00         1.00  \n",
       "\n",
       "[3 rows x 261 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \u001b[1m \u001b[32mduplicated\u001b[0m \u001b[0m \n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print_basic_info(contest_train,1,0,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \u001b[1m \u001b[32minfo\u001b[0m \u001b[0m \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9484 entries, 0749d313171551f to f91280c1f3aeac3\n",
      "Columns: 260 entries, FEATURE_0 to FEATURE_259\n",
      "dtypes: float64(260)\n",
      "memory usage: 18.9+ MB\n",
      "None\n",
      "\n",
      " \u001b[1m \u001b[32mhead\u001b[0m \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FEATURE_0</th>\n",
       "      <th>FEATURE_1</th>\n",
       "      <th>FEATURE_2</th>\n",
       "      <th>FEATURE_3</th>\n",
       "      <th>FEATURE_4</th>\n",
       "      <th>FEATURE_5</th>\n",
       "      <th>FEATURE_6</th>\n",
       "      <th>FEATURE_7</th>\n",
       "      <th>FEATURE_8</th>\n",
       "      <th>FEATURE_9</th>\n",
       "      <th>...</th>\n",
       "      <th>FEATURE_250</th>\n",
       "      <th>FEATURE_251</th>\n",
       "      <th>FEATURE_252</th>\n",
       "      <th>FEATURE_253</th>\n",
       "      <th>FEATURE_254</th>\n",
       "      <th>FEATURE_255</th>\n",
       "      <th>FEATURE_256</th>\n",
       "      <th>FEATURE_257</th>\n",
       "      <th>FEATURE_258</th>\n",
       "      <th>FEATURE_259</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0749d313171551f</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-46.95</td>\n",
       "      <td>-45.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>190.59</td>\n",
       "      <td>162.05</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ddb093edbbbe1ef</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>343.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>109.00</td>\n",
       "      <td>594.57</td>\n",
       "      <td>685.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cef8538a6054069</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>909.18</td>\n",
       "      <td>3260.45</td>\n",
       "      <td>3.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>297.00</td>\n",
       "      <td>10.21</td>\n",
       "      <td>300.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 260 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 FEATURE_0  FEATURE_1  FEATURE_2  FEATURE_3  FEATURE_4  \\\n",
       "ID                                                                       \n",
       "0749d313171551f       1.00       1.00       0.00       0.00       0.00   \n",
       "ddb093edbbbe1ef       0.00       0.00       1.00       0.00       0.00   \n",
       "cef8538a6054069       0.00       0.00       0.00       0.00       1.00   \n",
       "\n",
       "                 FEATURE_5  FEATURE_6  FEATURE_7  FEATURE_8  FEATURE_9  ...  \\\n",
       "ID                                                                      ...   \n",
       "0749d313171551f       0.00       0.00     -46.95     -45.02       0.00  ...   \n",
       "ddb093edbbbe1ef       0.00       0.00     343.63        NaN       3.00  ...   \n",
       "cef8538a6054069       0.00       0.00     909.18    3260.45       3.00  ...   \n",
       "\n",
       "                 FEATURE_250  FEATURE_251  FEATURE_252  FEATURE_253  \\\n",
       "ID                                                                    \n",
       "0749d313171551f         0.00         0.00       190.59       162.05   \n",
       "ddb093edbbbe1ef         5.00       109.00       594.57       685.50   \n",
       "cef8538a6054069         0.00       297.00        10.21       300.40   \n",
       "\n",
       "                 FEATURE_254  FEATURE_255  FEATURE_256  FEATURE_257  \\\n",
       "ID                                                                    \n",
       "0749d313171551f         1.00         0.00         1.00         1.00   \n",
       "ddb093edbbbe1ef         1.00         1.00         0.00         1.00   \n",
       "cef8538a6054069         0.00         0.00         0.00         1.00   \n",
       "\n",
       "                 FEATURE_258  FEATURE_259  \n",
       "ID                                         \n",
       "0749d313171551f         1.00         1.00  \n",
       "ddb093edbbbe1ef         1.00         2.00  \n",
       "cef8538a6054069         1.00         1.00  \n",
       "\n",
       "[3 rows x 260 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \u001b[1m \u001b[32mduplicated\u001b[0m \u001b[0m \n",
      "\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print_basic_info(contest_test,1,0,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m \u001b[34mTARGET\u001b[0m \u001b[0m \n",
      "\n",
      "0         0.71\n",
      "1         0.23\n",
      "2         0.06\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "ft_name_count(contest_train, 'TARGET' , 1, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The base consists of 24521 cases in the train and 9484 in the <br> 260 features test.\n",
    "\n",
    "There are no duplicates.\n",
    "\n",
    "Not all are filled. There are passes.\n",
    "\n",
    "**TARGET** - There is an imbalance. Strong. The most segment is 0. The least is 2.\n",
    "Therefore, most likely we will need to boost a part of the sample when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the gaps based on the 4 nearest neighbors.\n",
    "imputer = KNNImputer(n_neighbors=4)\n",
    "\n",
    "contest_train_after = imputer.fit_transform(contest_train.drop(['TARGET'], axis=1))\n",
    "contest_test_aftet = imputer.transform(contest_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24521, 260) (24521, 261) (9484, 260)\n"
     ]
    }
   ],
   "source": [
    "print(contest_train_after.shape, contest_train.shape, contest_test_aftet.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make it a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_contest_train_after = pd.DataFrame(contest_train_after, index = contest_train.index,\n",
    "                                      columns = contest_train.drop(['TARGET'], axis=1).columns.values)\n",
    "\n",
    "pd_contest_train_after['TARGET'] = contest_train['TARGET']\n",
    "\n",
    "pd_contest_test_after = pd.DataFrame(contest_test_aftet, index = contest_test.index ,\n",
    "                                      columns = contest_test.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check fullness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in pd_contest_train_after.columns:\n",
    "    if pd_contest_train_after[pd_contest_train_after[i].isnull() == True]['TARGET'].sum() > 0:\n",
    "        print(i, pd_contest_train_after[pd_contest_train_after[i].isnull() == True]['TARGET'].sum())\n",
    "        \n",
    "for i in contest_train.columns:\n",
    "    if contest_train[contest_train[i].isnull() == True]['TARGET'].sum() > 0:\n",
    "        print(i, contest_train[contest_train[i].isnull() == True]['TARGET'].sum())\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up from inf values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разабьем данные на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n",
    "    df.dropna(inplace=True)\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)\n",
    "\n",
    "cl_contest_train = clean_dataset(pd_contest_train_after)\n",
    "cl_contest_test = clean_dataset(pd_contest_test_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = cl_contest_train.drop(['TARGET'], axis=1)\n",
    "\n",
    "target = contest_train['TARGET']\n",
    "\n",
    "features_test = cl_contest_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#break down, stratify\n",
    "features_train_big, features_valid, target_train_big, target_valid = train_test_split(features, target , test_size=0.20,\n",
    "                                                                              random_state=515093, stratify = target)\n",
    "\n",
    "features_train, features_valid = np.array(features_train_big), np.array(features_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Масштабируем признаки\n",
    "numeric = features_train_big.columns\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train_big[numeric])\n",
    "\n",
    "display(features_train_big.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a decision tree as a model and do resampling.\n",
    "\n",
    "Less than 0 segments, more than 2 segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample(features, target, repeat_down, repeat_up):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    features_two = features[target == 2]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    target_two = target[target == 2]\n",
    "\n",
    "    features_resampled = pd.concat([features_zeros.sample(n =(int(len(features_zeros)*repeat_down)), \n",
    "                                                            replace=False,random_state=2)] + [features_ones] \n",
    "                                   + [features_two.sample(n =(int(len(features_two)*repeat_up)), \n",
    "                                                            replace=True,random_state=2)])\n",
    "    \n",
    "    target_resampled = pd.concat([target_zeros.sample(n =(int(len(target_zeros)*repeat_down)),\n",
    "                                                        replace=False)] + [target_ones] \n",
    "                                 + [target_two.sample(n =(int(len(target_two)*repeat_up)), \n",
    "                                                            replace=True)])\n",
    "    features_resampled, target_resampled = shuffle(features_resampled, target_resampled, random_state=12345)\n",
    "    features_resampled.reset_index(drop = True, inplace = True)\n",
    "    target_resampled.reset_index(drop = True, inplace = True)\n",
    "    return features_resampled, target_resampled\n",
    "\n",
    "base_up = pd.DataFrame()\n",
    "\n",
    "model_RFC = RandomForestClassifier(n_estimators = 50, random_state = 2)\n",
    "\n",
    "for i in np.arange(0.3, 0.5, 0.05):\n",
    "    for j in np.arange(2.2, 2.7, 0.05):\n",
    "        features_resampled, target_resampled = resample(features_train_big, target_train_big, i , j)\n",
    "        model_RFC.fit(features_resampled, target_resampled)\n",
    "        base_up.loc[str(i) + \" \" +str(j) ,'Precision'] = precision_score(target_valid, model_RFC.predict(features_valid), average='macro')\n",
    "        base_up.loc[str(i) + \" \" +str(j) ,'Recall'] = recall_score(target_valid, model_RFC.predict(features_valid), average='macro')\n",
    "        base_up.loc[str(i) + \" \" +str(j),'F1'] = f1_score(target_valid, model_RFC.predict(features_valid), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_resampled, target_resampled = resample(features_train_big, target_train_big, 0.35, 2.5)\n",
    "features_resampled, target_resampled = resample(features_train_big, target_train_big, 0.39, 2.2)\n",
    "\n",
    "features_resampled, target_resampled = np.array(features_resampled), target_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.43\n",
       "1         0.36\n",
       "2         0.21\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_resampled.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2.\"></a><br/>\n",
    "<font size=\"6\"><b>2. Model training </b></font>.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=2, random_state=1234, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a function that will record the training time, prediction rate, and prediction quality (RMSE)\n",
    "def put_in_base_test(base_res, model, features_train, target_train, features_valid, target_valid):\n",
    "    model.fit(features_train, target_train)\n",
    "    target = target_valid\n",
    "    features = features_valid\n",
    "    \n",
    "    proba = pd.DataFrame(model.predict_proba(features_valid), columns = ['0','1','2'])\n",
    "\n",
    "    proba['predict'] = pd.Series(model.predict(features_valid))\n",
    "    #proba['predict'] = proba['predict'].where(proba['0'] > 0.125, 0)\n",
    "    \n",
    "    prediction = test['predict']\n",
    "    accuracy, precision, recall, f1 = [], [], [], []\n",
    "    accuracy.append(accuracy_score(target, prediction))\n",
    "    precision.append(precision_score(target, prediction, average='macro'))\n",
    "    recall.append(recall_score(target, prediction, average='macro'))\n",
    "    f1.append(f1_score(target, prediction, average='macro'))\n",
    "    target_names = ['Seg - 0', 'Seg - 1', 'Seg - 2']\n",
    "    print(classification_report(target, prediction, target_names=target_names))\n",
    "    base_res.loc[str(model).split('(')[0],'accuracy'] = np.mean(accuracy)\n",
    "    base_res.loc[str(model).split('(')[0],'precision'] = np.mean(precision)\n",
    "    base_res.loc[str(model).split('(')[0],'recall'] = np.mean(recall)\n",
    "    base_res.loc[str(model).split('(')[0],'f1'] = np.mean(f1)\n",
    "    \n",
    "    return base_res, prediction, model\n",
    "\n",
    "# Display graphs for clarity\n",
    "def param_bars(base_name, name):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize = (10,3))\n",
    "    df = base_name\n",
    "    sns.barplot(data=df, palette=\"tab20\", linewidth=2.5)\n",
    "    plt.title(\"Model performance index - \" + str(name), fontsize=15)\n",
    "    plt.ylabel(\"%%\")\n",
    "    plt.xlabel(\"Settings\")\n",
    "    plt.ylim((0, 1.2))\n",
    "    c = 0\n",
    "    for i in df.columns:\n",
    "        plt.text( c - 0.1 , df[i].mean() + 0.1, \"{0:.0%}\".format(df[i].mean()))\n",
    "        c = c + 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, target_train = features_resampled, target_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier + RandomForestClassifier\n",
    "\n",
    "* Making a nested model. RandomForestClassifier to AdaBoostClassifier*\n",
    "\n",
    "* We select the parameters GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will select parameters using gridsearch\n",
    "parameters = {'max_depth':[i for i in range(15,26,1)] , 'n_estimators':[i for i in range(50,500,50)],\n",
    "              'max_features':[80,90,95,100], 'random_state':[1234]}\n",
    "\n",
    "clf = GridSearchCV(RandomForestClassifier(), cv = cv, param_grid = parameters, scoring = 'f1_macro')\n",
    "#clf.fit(features_train, target_train)\n",
    "#print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'n_estimators' : [i for i in range(5,25,5)], 'learning_rate': [0.1, 0.2, 0.3, 0.4, 0.6, 0.8, 1.0],\n",
    "       'algorithm' : ['SAMME', 'SAMME.R']}\n",
    "\n",
    "clf = AdaBoostClassifier(DecisionTreeClassifier())\n",
    "rs = GridSearchCV(clf, grid, cv=cv, scoring = 'f1_macro')\n",
    "\n",
    "#rs.fit(features_train, target_train)\n",
    "#AdaBoostRegressor_best_params1 = rs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check model (very long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_test = pd.DataFrame()\n",
    "\n",
    "model = AdaBoostClassifier(RandomForestClassifier(max_depth = 20, n_estimators = 500, max_features = 90, random_state = 2),\n",
    "    n_estimators=200, learning_rate=0.15, algorithm = 'SAMME.R') \n",
    "\n",
    "info_test, predictions, final_model = put_in_base_test(info_test, model, features_resampled, target_resampled, features_valid, target_valid)\n",
    "model = final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_bars(info_test,'Final Test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'ID': contest_test.index, \n",
    "                       'Predicted': pd.Series(final_model.predict(features_test), dtype='int32')})\n",
    "\n",
    "output.to_csv('sub_kiseleva.csv', index=False)\n",
    "print(\"Your submission was successfully saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"6.\"></a><br/>\n",
    "<font size=\"6\"><b>Output</b></font>.<br/>\n",
    "[<font size=\"2\">(to content)</font>](#1common.)\n",
    "\n",
    "\n",
    "* Gaps in columns were filled with KNNImputer - 4\n",
    "* When training the model, manual rebalancing of the classes was required. 0.39, 2.2,\n",
    "* The best performance for the model based on AdaBoostClassifier(RandomForestClassifier(max_depth = 19, n_estimators = 500, random_state = 1234), n_estimators=100, learning_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
